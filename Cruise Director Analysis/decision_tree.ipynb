{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decision_tree.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-SYtG-nyLDf",
        "outputId": "e7f18a2e-5e34-46d7-8fe6-5df66d32c7b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas\n",
        "pip install numpy\n",
        "pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this program on your local python\n",
        "# interpreter, provided you have installed\n",
        "# the required libraries.\n",
        "\n",
        "# Importing the required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "#for encoding\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "kHz9GI6tylfL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function importing Dataset\n",
        "def importdata():\n",
        "  #balance_data = pd.ExcelFile('/content/Cruise Director Analysis.xlsx',sep= ',', header = None)\n",
        "\n",
        "  # read an excel file and convert \n",
        "  # into a dataframe object\n",
        "  balance_data_actual = pd.DataFrame(pd.read_excel(\"/content/Cruise Director Analysis.xlsx\"))\n",
        "  \n",
        "  # drom na values\n",
        "  balance_data_actual = balance_data_actual.dropna()\n",
        "\n",
        "  # removed unwanted columns\n",
        "  balance_data = balance_data_actual.drop(['ID', 'Port of Embarkation', 'No of Siblings or Spouses on Board', 'No of Parents or Children on Board', 'Passenger Fare', 'ChildFare?'], axis = 1)\n",
        "\n",
        "  #label encoding\n",
        "  le = LabelEncoder()\n",
        "  balance_data['PurchasedPackage'] = le.fit_transform(balance_data['PurchasedPackage'])\n",
        "  balance_data['Economic Class'] = le.fit_transform(balance_data['Economic Class'])\n",
        "  balance_data['Sex'] = le.fit_transform(balance_data['Sex'])\n",
        "  balance_data['Age'] = le.fit_transform(balance_data['Age'])\n",
        "  \n",
        "  # Printing the dataswet shape\n",
        "  print (\"Dataset Length: \", len(balance_data))\n",
        "  print (\"Dataset Shape: \", balance_data.shape)\n",
        "  \n",
        "  # Printing the dataset obseravtions\n",
        "  print (\"Dataset: \",balance_data.head())\n",
        "  return balance_data"
      ],
      "metadata": {
        "id": "h1vRvBrtyp-l"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split the dataset\n",
        "def splitdataset(balance_data):\n",
        "  # Separating the target variable\n",
        "  X = balance_data.values[:, 0:3]\n",
        "  Y = balance_data.values[:, 3]\n",
        "\n",
        "\t# Splitting the dataset into train and test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "\tX, Y, test_size = 0.3, random_state = 100)\n",
        "  \n",
        "  return X, Y, X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "gK2WFP9Ky3IL"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform training with giniIndex.\n",
        "def train_using_gini(X_train, X_test, y_train):\n",
        "\n",
        "\t# Creating the classifier object\n",
        "\tclf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
        "\t\t\trandom_state = 100,max_depth=3, min_samples_leaf=5)\n",
        "\n",
        "\t# Performing training\n",
        "\tclf_gini.fit(X_train, y_train)\n",
        "\treturn clf_gini"
      ],
      "metadata": {
        "id": "jNSHECWdy47g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform training with entropy.\n",
        "def tarin_using_entropy(X_train, X_test, y_train):\n",
        "\n",
        "\t# Decision tree with entropy\n",
        "\tclf_entropy = DecisionTreeClassifier(\n",
        "\t\t\tcriterion = \"entropy\", random_state = 100,\n",
        "\t\t\tmax_depth = 3, min_samples_leaf = 5)\n",
        "\n",
        "\t# Performing training\n",
        "\tclf_entropy.fit(X_train, y_train)\n",
        "\treturn clf_entropy"
      ],
      "metadata": {
        "id": "ciHSH7Ohy7Hx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make predictions\n",
        "def prediction(X_test, clf_object):\n",
        "\n",
        "\t# Predicton on test with giniIndex\n",
        "\ty_pred = clf_object.predict(X_test)\n",
        "\tprint(\"Predicted values:\")\n",
        "\tprint(y_pred)\n",
        "\treturn y_pred"
      ],
      "metadata": {
        "id": "gvTppBZvy9Ff"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def cal_accuracy(y_test, y_pred):\n",
        "\t\n",
        "\tprint(\"Confusion Matrix: \",\n",
        "\t\tconfusion_matrix(y_test, y_pred))\n",
        "\t\n",
        "\tprint (\"Accuracy : \",\n",
        "\taccuracy_score(y_test,y_pred)*100)\n",
        "\t\n",
        "\tprint(\"Report : \",\n",
        "\tclassification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "QhPpinABy_Kc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Driver code\n",
        "def main():\n",
        "  # Building Phase\n",
        "\n",
        "  data = importdata()\n",
        "  \n",
        "  X, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n",
        "  clf_gini = train_using_gini(X_train, X_test, y_train)\n",
        "  clf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n",
        "  \n",
        "  # Operational Phase\n",
        "  print(\"Results Using Gini Index:\")\n",
        "  \n",
        "  # Prediction using gini\n",
        "  y_pred_gini = prediction(X_test, clf_gini)\n",
        "  cal_accuracy(y_test, y_pred_gini)\n",
        "  \n",
        "  print(\"Results Using Entropy:\")\n",
        "  # Prediction using entropy\n",
        "  y_pred_entropy = prediction(X_test, clf_entropy)\n",
        "  cal_accuracy(y_test, y_pred_entropy)"
      ],
      "metadata": {
        "id": "dnuUXGDoy_8r"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling main function\n",
        "if __name__==\"__main__\":\n",
        "\tmain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uFgW5Q6zB15",
        "outputId": "f544fda5-c196-42c8-d866-5f62180aa684"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Length:  1046\n",
            "Dataset Shape:  (1046, 4)\n",
            "Dataset:     Economic Class  Sex  Age  PurchasedPackage\n",
            "0               2    1   49                 0\n",
            "1               0    1   38                 1\n",
            "2               0    1   41                 0\n",
            "3               2    0   50                 1\n",
            "4               0    1   56                 0\n",
            "Results Using Gini Index:\n",
            "Predicted values:\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0\n",
            " 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
            " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1\n",
            " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
            " 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Confusion Matrix:  [[188   7]\n",
            " [ 57  62]]\n",
            "Accuracy :  79.61783439490446\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.96      0.85       195\n",
            "           1       0.90      0.52      0.66       119\n",
            "\n",
            "    accuracy                           0.80       314\n",
            "   macro avg       0.83      0.74      0.76       314\n",
            "weighted avg       0.82      0.80      0.78       314\n",
            "\n",
            "Results Using Entropy:\n",
            "Predicted values:\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0\n",
            " 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
            " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1\n",
            " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
            " 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Confusion Matrix:  [[188   7]\n",
            " [ 57  62]]\n",
            "Accuracy :  79.61783439490446\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.96      0.85       195\n",
            "           1       0.90      0.52      0.66       119\n",
            "\n",
            "    accuracy                           0.80       314\n",
            "   macro avg       0.83      0.74      0.76       314\n",
            "weighted avg       0.82      0.80      0.78       314\n",
            "\n"
          ]
        }
      ]
    }
  ]
}